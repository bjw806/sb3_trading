{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:28:09.043554700Z",
     "start_time": "2024-03-22T12:28:07.170880Z"
    }
   },
   "outputs": [],
   "source": [
    "# module import\n",
    "\n",
    "import warnings\n",
    "\n",
    "import gym_trading_env  # noqa\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gym_trading_env.renderer import Renderer\n",
    "from gymnasium.envs.registration import register\n",
    "from sb3_contrib import QRDQN, RecurrentPPO\n",
    "from sb3_contrib.qrdqn import MlpPolicy\n",
    "from sb3_contrib.ppo_recurrent import MlpLstmPolicy\n",
    "from sklearn.preprocessing import robust_scale\n",
    "from stable_baselines3.common.utils import get_device\n",
    "# from stable_baselines3.ppo import MlpPolicy\n",
    "from tqdm import TqdmExperimentalWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7369c5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:28:10.551574200Z",
     "start_time": "2024-03-22T12:28:10.542546500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "\n",
    "\n",
    "def SMA(df, ndays):\n",
    "    SMA = pd.Series(df.close.rolling(ndays).mean(), name=\"SMA_\" + str(ndays))\n",
    "    return SMA.astype(float).round(2)\n",
    "\n",
    "\n",
    "def BBANDS(df, n):\n",
    "    MA = df.close.rolling(window=n).mean()\n",
    "    SD = df.close.rolling(window=n).std()\n",
    "    upperBand = MA + (2 * SD)\n",
    "    lowerBand = MA - (2 * SD)\n",
    "    return upperBand.astype(float).round(2), lowerBand.astype(float).round(2)\n",
    "\n",
    "\n",
    "def RSI(df, periods=14):\n",
    "    close_delta = df.close.diff()\n",
    "    up = close_delta.clip(lower=0)\n",
    "    down = -1 * close_delta.clip(upper=0)\n",
    "    ma_up = up.ewm(com=periods - 1, adjust=True, min_periods=periods).mean()\n",
    "    ma_down = down.ewm(com=periods - 1, adjust=True, min_periods=periods).mean()\n",
    "\n",
    "    _rsi = ma_up / ma_down\n",
    "    return (100 - (100 / (1 + _rsi))).astype(float).round(2)\n",
    "\n",
    "\n",
    "def MACD(df):\n",
    "    k = df[\"close\"].ewm(span=12, adjust=False, min_periods=12).mean()\n",
    "    d = df[\"close\"].ewm(span=26, adjust=False, min_periods=26).mean()\n",
    "    macd = k - d\n",
    "    macd_s = macd.ewm(span=9, adjust=False, min_periods=9).mean()\n",
    "    macd_h = macd - macd_s\n",
    "    #return df.index.map(macd), df.index.map(macd_s), df.index.map(macd_h)\n",
    "    return macd.astype(float).round(2), macd_s.astype(float).round(2), macd_h.astype(float).round(2)\n",
    "\n",
    "\n",
    "def add_robust_features(df):\n",
    "    df[\"feature_close\"] = robust_scale(df.close.pct_change())\n",
    "    df[\"feature_open\"] = robust_scale(df.open/df.close)\n",
    "    df[\"feature_high\"] = robust_scale(df.high/df.close)\n",
    "    df[\"feature_low\"] = robust_scale(df.low/df.close)\n",
    "    df[\"feature_volume\"] = robust_scale(df.volume / df.volume.rolling(7*24).max())\n",
    "    df.dropna(inplace= True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    columns = [x for x in df.columns if \"feature\" in x]\n",
    "    for feature_name in columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "\n",
    "\n",
    "def robust(df):\n",
    "    result = df.copy()\n",
    "    columns = [x for x in df.columns if \"feature\" in x]\n",
    "    for feature_name in columns:\n",
    "        result[feature_name] = robust_scale(df[feature_name])\n",
    "    return result\n",
    "\n",
    "\n",
    "def stochastic_fast_k(df, n=5):\n",
    "      fast_k = ((df.close - df.low.rolling(n).min()) / (df.high.rolling(n).max() - df.low.rolling(n).min())) * 100 \n",
    "      return fast_k \n",
    "\n",
    "\n",
    "def stochastic_slow_k(fast_k, n=3):\n",
    "    slow_k = fast_k.rolling(n).mean()  \n",
    "    return slow_k \n",
    "\n",
    "\n",
    "def stochastic_slow_d(slow_k, n=3):\n",
    "    slow_d = slow_k.rolling(n).mean() \n",
    "    return slow_d\n",
    "\n",
    "\n",
    "def OBV(df):\n",
    "    volume_diff = df.volume.diff()\n",
    "    direction = np.zeros(len(df))\n",
    "    direction[1:] = np.where(df.close[1:] > df.close[:-1].values, 1, -1)\n",
    "    direction[volume_diff == 0] = 0\n",
    "    obv = (volume_diff * direction).cumsum() \n",
    "    return obv.astype(float).round(2)\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    df[\"volume\"] = df.volume.astype(float).round(2)\n",
    "    df[\"feature_close\"] = df.close\n",
    "    df[\"feature_open\"] = df.open\n",
    "    df[\"feature_high\"] = df.high\n",
    "    df[\"feature_low\"] = df.low\n",
    "    df[\"feature_volume\"] = df.volume\n",
    "    df[\"feature_SMA_7\"] = SMA(df, 7)\n",
    "    df[\"feature_SMA_25\"] = SMA(df, 25)\n",
    "    df[\"feature_SMA_99\"] = SMA(df, 99)\n",
    "    df[\"feature_MiddleBand\"], df[\"feature_LowerBand\"] = BBANDS(df, 21)\n",
    "    df[\"feature_MACD\"], df[\"feature_MACD_S\"], df[\"feature_MACD_H\"] = MACD(df)\n",
    "    df = df.dropna()\n",
    "\n",
    "    df_robust = robust(df)\n",
    "\n",
    "    df_robust[\"feature_RSI_6\"] = RSI(df, periods=6)\n",
    "    df_robust[\"feature_RSI_12\"] = RSI(df, periods=12)\n",
    "    df_robust[\"feature_RSI_24\"] = RSI(df, periods=24)\n",
    "\n",
    "    return df_robust\n",
    "\n",
    "\n",
    "def only_sub_indicators(df):\n",
    "    # df['fast_k'] = stochastic_fast_k(df, 5)\n",
    "    # df['feature_slow_stochastic_k'] = stochastic_slow_k(df.fast_k, 3)\n",
    "    # df['feature_slow_stochastic_d'] = stochastic_slow_d(df.feature_slow_stochastic_k, 3)\n",
    "    # df[\"feature_OBV\"] = OBV(df)\n",
    "    df[\"feature_RSI_6\"] = RSI(df, periods=6)\n",
    "    df[\"feature_RSI_12\"] = RSI(df, periods=12)\n",
    "    df[\"feature_RSI_24\"] = RSI(df, periods=24)\n",
    "    df[\"feature_MACD\"], df[\"feature_MACD_S\"], df[\"feature_MACD_H\"] = MACD(df)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc7b86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:19:48.622619700Z",
     "start_time": "2024-03-22T12:19:48.617425400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reward Function\n",
    "\n",
    "def reward_only_position_changed(history):\n",
    "    dd = (\n",
    "        history[\"portfolio_valuation\", 0]\n",
    "        if history[\"portfolio_valuation\", 0] > history[\"prev_position_valuation\", -2]\n",
    "        else history[\"prev_position_valuation\", -2]\n",
    "    )\n",
    "\n",
    "    return (history[\"portfolio_valuation\", -1] - history[\"prev_position_valuation\", -2]) / dd  # / sqrt(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b45d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward Function\n",
    "\n",
    "def reward_only_position_changed_roe(history):\n",
    "    if history[\"portfolio_valuation\", -1] <= 0:\n",
    "        return -1\n",
    "    prev_position = history[\"position\", -2]\n",
    "    curr_position = history[\"position\", -1]\n",
    "\n",
    "    position_roe = (\n",
    "        history[\"portfolio_valuation\", -1] / history[\"entry_valuation\", -1] - 1\n",
    "    )\n",
    "    total_roe = (\n",
    "        history[\"portfolio_valuation\", -1] / history[\"portfolio_valuation\", 0] - 1\n",
    "    )\n",
    "\n",
    "    if prev_position == curr_position:\n",
    "        return 0\n",
    "    else:\n",
    "        if history[\"portfolio_valuation\", -2] < history[\"portfolio_valuation\", -1]:\n",
    "            if total_roe > 0:\n",
    "                return position_roe\n",
    "            else:\n",
    "                return total_roe\n",
    "        else:\n",
    "            return position_roe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a928a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_by_pnl(history):\n",
    "    if history[\"portfolio_valuation\", -1] <= 0:\n",
    "        return -1\n",
    "\n",
    "    prev_position = history[\"position\", -2]\n",
    "    curr_position = history[\"position\", -1]\n",
    "\n",
    "    if prev_position == curr_position:\n",
    "        return 0\n",
    "    else:\n",
    "        return  (history[\"portfolio_valuation\", -1] - history[\"entry_valuation\", -1]) /history[\"portfolio_valuation\", 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56260b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_done(history):\n",
    "    if history[\"portfolio_valuation\", -1] <= 0:\n",
    "        return -10\n",
    "\n",
    "    return (history[\"portfolio_valuation\", -1] - history[\"portfolio_valuation\", 0]) / history[\"portfolio_valuation\", 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d278f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_volatility(portfolio_valuations):\n",
    "    \"\"\"\n",
    "    포트폴리오 가치의 리스트를 기반으로 변동성(표준편차)를 계산합니다.\n",
    "    \"\"\"\n",
    "    if len(portfolio_valuations) < 2:\n",
    "        return 0  # 데이터가 충분하지 않은 경우 변동성을 0으로 반환\n",
    "    log_returns = np.diff(np.log(portfolio_valuations))\n",
    "    volatility = np.std(log_returns)\n",
    "    return volatility\n",
    "\n",
    "def reward_function_volatility(history):\n",
    "    \"\"\"\n",
    "    변경된 보상 함수: 동적으로 N을 계산하고, 손해가 났을 때 음수 보상을 부여합니다.\n",
    "    \"\"\"\n",
    "    total_steps = history[-1]['step'] + 1  # 총 스텝 수\n",
    "    N_ratio = 0.1  # 전체 데이터의 마지막 10%를 사용\n",
    "    N = max(int(total_steps * N_ratio), 1)  # 적어도 한 스텝은 포함되도록\n",
    "\n",
    "    # 최근 N개 스텝의 포트폴리오 가치 추출\n",
    "    portfolio_valuations = [history[max(0, len(history) - N + i)]['portfolio_valuation'] for i in range(N)]\n",
    "    \n",
    "    # 변동성 계산\n",
    "    volatility = calculate_volatility(portfolio_valuations)\n",
    "    \n",
    "    # 현재 스텝 정보 추출\n",
    "    current_portfolio_valuation = history[-1]['portfolio_valuation']\n",
    "    initial_portfolio_valuation = history[0]['portfolio_valuation']\n",
    "    current_step = history[-1]['step']\n",
    "\n",
    "    # 수익률 계산\n",
    "    total_roe = (current_portfolio_valuation / initial_portfolio_valuation - 1)\n",
    "\n",
    "    # 장기 실행 보상 및 변동성에 기반한 보상 조정\n",
    "    long_term_bonus = max(1, current_step / 100)\n",
    "    stability_bonus = 1 / (volatility + 0.01)  # 분모가 0이 되지 않도록\n",
    "\n",
    "    # 손실이 발생했을 경우 음수 보상 부여\n",
    "    if total_roe < 0:\n",
    "        reward = total_roe * stability_bonus * long_term_bonus\n",
    "    else:\n",
    "        reward = max(0, total_roe) * stability_bonus * long_term_bonus\n",
    "\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d4066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_volatility_and_sharpe(portfolio_valuations, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    포트폴리오 가치의 리스트를 기반으로 변동성(표준편차)와 샤프 비율을 계산합니다.\n",
    "    risk_free_rate는 연간 무위험 수익률을 의미하며, 기본값을 0으로 설정합니다.\n",
    "    \"\"\"\n",
    "    if len(portfolio_valuations) < 2:\n",
    "        return 0, 0  # 데이터가 충분하지 않은 경우 변동성과 샤프 비율을 0으로 반환\n",
    "\n",
    "    log_returns = np.diff(np.log(portfolio_valuations))\n",
    "    volatility = np.std(log_returns)\n",
    "    mean_return = np.mean(log_returns)\n",
    "    sharpe_ratio = (mean_return - risk_free_rate / 252) / volatility if volatility != 0 else 0\n",
    "\n",
    "    return volatility, sharpe_ratio\n",
    "\n",
    "def reward_function_sharp(history, N_ratio=0.1, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    개선된 보상 함수: 동적으로 N을 계산하고, 손해가 났을 때 음수 보상을 부여하며,\n",
    "    리스크 조정 수익률(샤프 비율)을 고려합니다.\n",
    "    \"\"\"\n",
    "    total_steps = history[-1]['step'] + 1\n",
    "    N = max(int(total_steps * N_ratio), 1)\n",
    "\n",
    "    portfolio_valuations = [history[max(0, len(history) - N + i)]['portfolio_valuation'] for i in range(N)]\n",
    "    \n",
    "    volatility, sharpe_ratio = calculate_volatility_and_sharpe(portfolio_valuations, risk_free_rate)\n",
    "    \n",
    "    current_portfolio_valuation = history[-1]['portfolio_valuation']\n",
    "    initial_portfolio_valuation = history[0]['portfolio_valuation']\n",
    "    current_step = history[-1]['step']\n",
    "\n",
    "    total_roe = (current_portfolio_valuation / initial_portfolio_valuation - 1)\n",
    "    long_term_bonus = max(1, current_step / 100)\n",
    "\n",
    "    reward = total_roe * long_term_bonus\n",
    "\n",
    "    # 손실 시 음수 보상 부여와 리스크 조정 보상 적용\n",
    "    if total_roe < 0:\n",
    "        reward *= (1 + sharpe_ratio)  # 손실이 있을 경우 샤프 비율을 이용해 조정\n",
    "    else:\n",
    "        reward *= (1 + abs(sharpe_ratio))  # 수익이 있을 경우 절대값 샤프 비율을 이용해 조정\n",
    "\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf982e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_volatility_and_sharpe(portfolio_valuations, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    포트폴리오 가치의 리스트를 기반으로 변동성(표준편차)와 샤프 비율을 계산합니다.\n",
    "    \"\"\"\n",
    "    if len(portfolio_valuations) < 2:\n",
    "        return 0, 0  # 데이터가 충분하지 않은 경우 변동성과 샤프 비율을 0으로 반환\n",
    "\n",
    "    log_returns = np.diff(np.log(portfolio_valuations))\n",
    "    volatility = np.std(log_returns)\n",
    "    mean_return = np.mean(log_returns)\n",
    "    sharpe_ratio = (mean_return - risk_free_rate / 252) / volatility if volatility != 0 else 0\n",
    "\n",
    "    return volatility, sharpe_ratio\n",
    "\n",
    "def calculate_max_drawdown(portfolio_valuations):\n",
    "    \"\"\"\n",
    "    최대 드로다운을 계산합니다.\n",
    "    \"\"\"\n",
    "    max_value = np.max(portfolio_valuations)\n",
    "    drawdowns = 1 - (portfolio_valuations / max_value)\n",
    "    max_drawdown = np.max(drawdowns)\n",
    "    return max_drawdown\n",
    "\n",
    "def reward_function_sharp_with_volatility(history, N_ratio=0.1, risk_free_rate=0.0, volatility_penalty=0.5):\n",
    "    total_steps = history[-1][\"step\"] + 1\n",
    "    N = max(int(total_steps * N_ratio), 1)\n",
    "\n",
    "    portfolio_valuations = [\n",
    "        history[max(0, len(history) - N + i)][\"portfolio_valuation\"] for i in range(N)\n",
    "    ]\n",
    "\n",
    "    volatility, sharpe_ratio = calculate_volatility_and_sharpe(\n",
    "        portfolio_valuations, risk_free_rate\n",
    "    )\n",
    "\n",
    "    current_portfolio_valuation = history[-1][\"portfolio_valuation\"]\n",
    "    initial_portfolio_valuation = history[0][\"portfolio_valuation\"]\n",
    "    current_step = history[-1][\"step\"]\n",
    "\n",
    "    total_roe = current_portfolio_valuation / initial_portfolio_valuation - 1\n",
    "    long_term_bonus = max(1, current_step / 100)\n",
    "\n",
    "    reward = total_roe * long_term_bonus\n",
    "\n",
    "    # 새로운 로직: 변동성을 반영하여 보상 조정\n",
    "    volatility_adjustment = 1 - (volatility * volatility_penalty)\n",
    "    reward *= volatility_adjustment\n",
    "\n",
    "    if total_roe < 0:\n",
    "        reward *= 1 + sharpe_ratio\n",
    "    else:\n",
    "        reward *= 1 + abs(sharpe_ratio)\n",
    "\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d17c57a85d6a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:28:36.716171100Z",
     "start_time": "2024-03-22T12:28:35.098437100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gte import MultiDatasetDiscretedTradingEnv\n",
    "# Enviornment\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "\n",
    "vec_env = make_vec_env(\n",
    "    MultiDatasetDiscretedTradingEnv,\n",
    "    n_envs=16,\n",
    "    # vec_env_cls=SubprocVecEnv,\n",
    "    env_kwargs=dict(\n",
    "        dataset_dir=\"./data/train/day/**/**/*.pkl\",\n",
    "        preprocess=only_sub_indicators,\n",
    "        reward_function=reward_only_position_changed,\n",
    "        positions=[-5, -2, 0, 2, 5],\n",
    "        trading_fees=0.0001,\n",
    "        borrow_interest_rate=0.00003,\n",
    "        window_size=180,\n",
    "        portfolio_initial_value=1000,\n",
    "        verbose=2,\n",
    "    ),\n",
    "    wrapper_class=gym.wrappers.FlattenObservation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "register(\n",
    "    id='MultiDatasetDiscretedTradingEnv',\n",
    "    entry_point='gte:MultiDatasetDiscretedTradingEnv',\n",
    "    disable_env_checker = True\n",
    ")\n",
    "env = gym.make(\n",
    "    \"MultiDatasetDiscretedTradingEnv\",\n",
    "    dataset_dir=\"./data/train/month/**/*.pkl\",\n",
    "    preprocess=only_sub_indicators,\n",
    "    reward_function=reward_function_volatility,\n",
    "    positions=[-5, -2, 0, 2, 5],\n",
    "    trading_fees=0.0001,\n",
    "    borrow_interest_rate=0.00003,\n",
    "    window_size=240,\n",
    "    portfolio_initial_value=1000,\n",
    "    verbose=2,\n",
    ")\n",
    "env = gym.wrappers.FlattenObservation(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad699c4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:28:45.084595600Z",
     "start_time": "2024-03-22T12:28:44.506754800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=TqdmExperimentalWarning)\n",
    "model = QRDQN(\n",
    "    MlpPolicy,\n",
    "    vec_env,\n",
    "    buffer_size=10_000_000,  # 1_000_000\n",
    "    # n_steps=1024,\n",
    "    # batch_size=4,\n",
    "    verbose=0,\n",
    "    device=\"cpu\",\n",
    "    tensorboard_log=\"./tensorboard/\",\n",
    "    # optimize_memory_usage=True,\n",
    "    # learning_rate =0.0000001, #0.00005\n",
    "    # use_sde=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=TqdmExperimentalWarning)\n",
    "model = RecurrentPPO(\n",
    "    MlpLstmPolicy,\n",
    "    vec_env,\n",
    "    # n_steps=1024*16,\n",
    "    # batch_size=4,\n",
    "    verbose=0,\n",
    "    # device=\"cpu\",\n",
    "    tensorboard_log=\"./tensorboard/\",\n",
    "    # optimize_memory_usage=True,\n",
    "    # learning_rate =0.0000001, #0.00005\n",
    "    # use_sde=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce1b4d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T12:28:47.121578400Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=1000000, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a12aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = vec_env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    # vec_env.render()\n",
    "import pprint\n",
    "pprint.pprint(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993fb11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = Renderer(render_logs_dir=\"render_logs\")\n",
    "renderer.add_metric(\n",
    "    \"Annual Market Return\",\n",
    "    lambda df: f\"{((df['close'].iloc[-1] / df['close'].iloc[0]) ** (pd.Timedelta(days=365) / (df.index.values[-1] - df.index.values[0])) - 1) * 100:0.2f}%\",\n",
    ")\n",
    "renderer.add_metric(\n",
    "    \"Annual Portfolio Return\",\n",
    "    lambda df: f\"{((df['portfolio_valuation'].iloc[-1] / df['portfolio_valuation'].iloc[0]) ** (pd.Timedelta(days=365) / (df.index.values[-1] - df.index.values[0])) - 1) * 100:0.2f}%\",\n",
    ")\n",
    "renderer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9af8c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/RPPO/2024_04_11_1.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
